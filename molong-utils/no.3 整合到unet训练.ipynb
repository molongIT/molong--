{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 放到unet forward中会梯度不回传，废弃\"\"\"\n",
    "def apply_feature_map_to_logits(logits, feature_map):\n",
    "    \"\"\"\n",
    "    应用 feature_map 到 UNet 的输出 logits 以修正前景和背景的概率。\n",
    "    \n",
    "    参数:\n",
    "    - logits: torch.Tensor, UNet 的输出，形状为 [B, C, H, W]，其中 B 是批大小，C 是通道数，H 和 W 是特征图的高度和宽度。\n",
    "    - feature_map: numpy.array, 特征图，大小与输入图像一致。\n",
    "\n",
    "    返回:\n",
    "    - modified_logits: torch.Tensor, 经过 feature_map 修正后的 logits。\n",
    "    \"\"\"\n",
    "    # 确保 logits 的形状为 [B, 2, H, W]\n",
    "    assert logits.shape[1] == 2, \"logits 必须有 2 个通道 (前景和背景)。\"\n",
    "\n",
    "    # 将 numpy 的 feature_map 转换为 torch.Tensor，并调整形状\n",
    "    feature_map_tensor = torch.tensor(feature_map, dtype=logits.dtype, device=logits.device)\n",
    "\n",
    "    # 调整 feature_map 的大小以匹配 logits 的空间维度 (H, W)\n",
    "    feature_map_resized = F.interpolate(feature_map_tensor.unsqueeze(0).unsqueeze(0), size=logits.shape[2:], mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "    # 对前景通道 (channel=1) 应用 feature_map 权重\n",
    "    logits[:, 1, :, :] = logits[:, 1, :, :] * feature_map_resized\n",
    "\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 放到unet forward中会梯度不回传，废弃\"\"\"\n",
    "\"\"\" Parts of the U-Net parts \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        # 将 feature_map 应用到 logits\n",
    "        binaryImage = f(logits)\n",
    "        pred = np.array(binaryImage) \n",
    "        _, binary = cv2.threshold(pred, 127, 255, cv2.THRESH_BINARY)\n",
    "        segment_graph = segment_and_visualize_vessels(binary.copy())\n",
    "        updated_graph,feature_map= apply_static_graph_rules(segment_graph,debug=False)\n",
    "        modified_logits = apply_feature_map_to_logits(logits, feature_map)\n",
    "        return modified_logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像已保存到: /home/pxl/myProject/血管分割/molong-深度插值/molong-utils/combined_image.png\n"
     ]
    }
   ],
   "source": [
    "import 差分约束 as DifferentialConnection\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from skimage.measure import label, regionprops\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.measure import label, regionprops\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import networkx as nx\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.spatial import distance\n",
    "from numpy.polynomial.polynomial import Polynomial\n",
    "from no_one提取图结构 import segment_and_visualize_vessels,crop_image,visualize_segments_andNo,visualize_segment_graph\n",
    "\"\"\" 作为loss加权 \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def f(logits):\n",
    "    \"\"\"\n",
    "    从 2 通道的 logits 提取二值分割结果。\n",
    "    \n",
    "    参数:\n",
    "    - logits: torch.Tensor, 形状为 [B, 2, H, W]，表示网络输出的 logits。\n",
    "    \n",
    "    返回:\n",
    "    - binary_image: numpy.array, 二值分割结果 (0 和 255) 的图像。\n",
    "    \"\"\"\n",
    "    # 1. 对 logits 应用 softmax 操作以得到每个通道的概率\n",
    "    probabilities = F.softmax(logits, dim=1)  # 输出形状仍为 [B, 2, H, W]\n",
    "    # 2. 获取前景通道 (channel=1) 的概率\n",
    "    foreground_prob = probabilities[:, 1, :, :]  # 形状为 [B, H, W]\n",
    "    # 3. 设定一个阈值 (例如 0.5) 来确定前景和背景\n",
    "    threshold = 0.5\n",
    "    binary_image = (foreground_prob > threshold).float() * 255  # 将前景设置为 255，背景为 0\n",
    "    # 4. 转换为 numpy array，并确保类型为 uint8\n",
    "    binary_image = binary_image.squeeze(0).cpu().numpy().astype(np.uint8)  # 移除 batch 维度\n",
    "    return binary_image\n",
    "def generate_line_pixels(point1, point2):\n",
    "    \"\"\"\n",
    "    给定两个端点，生成在这两个端点之间的所有像素坐标。\n",
    "    \n",
    "    参数:\n",
    "    - point1: 第一个端点的坐标 (x1, y1)。\n",
    "    - point2: 第二个端点的坐标 (x2, y2)。\n",
    "    \n",
    "    返回:\n",
    "    - pixels: 端点之间所有像素的坐标列表 [(x, y), ...]。\n",
    "    \"\"\"\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    pixels = []\n",
    "\n",
    "    # 使用 Bresenham 算法来生成直线上的所有像素\n",
    "    dx = abs(x2 - x1)\n",
    "    dy = abs(y2 - y1)\n",
    "    sx = 1 if x1 < x2 else -1\n",
    "    sy = 1 if y1 < y2 else -1\n",
    "    err = dx - dy\n",
    "\n",
    "    while True:\n",
    "        # 将当前坐标添加到像素列表中\n",
    "        pixels.append((x1, y1))\n",
    "        \n",
    "        # 如果到达终点，则退出\n",
    "        if (x1, y1) == (x2, y2):\n",
    "            break\n",
    "        \n",
    "        e2 = 2 * err\n",
    "        if e2 > -dy:\n",
    "            err -= dy\n",
    "            x1 += sx\n",
    "        if e2 < dx:\n",
    "            err += dx\n",
    "            y1 += sy\n",
    "\n",
    "    return pixels\n",
    "def find_closest_segment_endpoints(graph, target_node, max_distance):\n",
    "    \"\"\"\n",
    "    找到与目标节点的两个端点最近的段。\n",
    "    \n",
    "    参数:\n",
    "    - graph: nx.Graph, 当前的图。\n",
    "    - target_node: int, 当前要查找的目标节点。\n",
    "    - max_distance: float, 最大允许的空间距离。\n",
    "    \n",
    "    返回:\n",
    "    - closest_nodes: list, 与目标节点的两个端点最近的段的索引列表。\n",
    "    \"\"\"\n",
    "    target_endpoints = graph.nodes[target_node]['endpoints']\n",
    "    closest_nodes = []\n",
    "\n",
    "    # 遍历当前段的两个端点\n",
    "    for endpoint in target_endpoints:\n",
    "        min_distance = float('inf')\n",
    "        closest_node = None\n",
    "\n",
    "        # 遍历所有其他节点，寻找与当前端点最近的段\n",
    "        for node, features in graph.nodes(data=True):\n",
    "            if node == target_node:\n",
    "                continue\n",
    "\n",
    "            node_endpoints = features['endpoints']\n",
    "            # 计算与当前端点的最小距离\n",
    "            for ep in node_endpoints:\n",
    "                distance = np.sqrt((endpoint[0] - ep[0])**2 + (endpoint[1] - ep[1])**2)\n",
    "                if distance < min_distance and distance <= max_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_node = node\n",
    "\n",
    "        # 如果找到了符合条件的最近节点，则添加到结果列表\n",
    "        if closest_node is not None:\n",
    "            closest_nodes.append((closest_node, min_distance))\n",
    "\n",
    "    return closest_nodes\n",
    "# 先验修复，生成featuremap\n",
    "def apply_static_graph_rules(pred, graph, min_pixel_count=3, direction_threshold=np.pi/8, max_distance=20,debug=False):\n",
    "    \"\"\"\n",
    "    应用静态图规则对图进行优化，包括连通性和孤立团删除。\n",
    "    \n",
    "    参数:\n",
    "    - graph: nx.Graph, 当前的段图结构。\n",
    "    - unet_feature_size: tuple, UNet 特征图的大小 (H, W)。\n",
    "    - min_pixel_count: int, 最小像素数量阈值。\n",
    "    - direction_threshold: float, 方向相似度阈值。\n",
    "    - max_distance: float, 最大允许的空间距离。\n",
    "    \n",
    "    返回:\n",
    "    - updated_graph: nx.Graph, 经过规则优化后的图。\n",
    "    - feature_map: np.array, 更新后的 feature_map。\n",
    "    \"\"\"\n",
    "    # 1. 初始化空的 feature_map\n",
    "    unet_feature_size = (pred.shape[0],pred.shape[1])\n",
    "    feature_map = np.zeros(unet_feature_size)\n",
    "    \n",
    "    # 复制图用于修改\n",
    "    updated_graph = graph.copy()\n",
    "    \n",
    "    # 规则 1：连通规则 - 连接空间上接近且方向相似的段\n",
    "    for node_i, features_i in updated_graph.nodes(data=True):\n",
    "        # 2. 顶点获取坐标\n",
    "        point1, point2 = features_i['endpoints']\n",
    "        closest_nodes = find_closest_segment_endpoints(updated_graph, node_i, max_distance)\n",
    "        \n",
    "        for closest_node, _ in closest_nodes:\n",
    "            k_i = features_i['direction_k']\n",
    "            k_closest = updated_graph.nodes[closest_node]['direction_k']\n",
    "            \n",
    "            # 2. 顶点获取坐标\n",
    "            point3, point4 = updated_graph.nodes[closest_node]['endpoints']\n",
    "\n",
    "            # 检查方向相似性\n",
    "            if abs(k_i - k_closest) < direction_threshold:\n",
    "                updated_graph.add_edge(node_i, closest_node, weight=1)\n",
    "                if(debug):\n",
    "                    print(f\"添加边: ({node_i}, {closest_node}) - 符合连通条件\")\n",
    "\n",
    "                # 3. 拟合直线路径\n",
    "                pixels1 = generate_line_pixels(point1, point3)\n",
    "                pixels2 = generate_line_pixels(point2, point3)\n",
    "                pixels3 = generate_line_pixels(point1, point4)\n",
    "                pixels4 = generate_line_pixels(point2, point4)\n",
    "                \n",
    "                # 遍历所有像素列表，更新 feature_map\n",
    "                for pixels in [pixels1, pixels2, pixels3, pixels4]:\n",
    "                    for (x, y) in pixels:\n",
    "                        if 0 <= x < feature_map.shape[0] and 0 <= y < feature_map.shape[1]:\n",
    "                            feature_map[x, y] = 1.5\n",
    "                            if(debug):\n",
    "                                print(f\"设置权重: feature_map[{x}, {y}] = 1.5\")  # 打印日志\n",
    "\n",
    "    # 规则 2：删除孤立团 - 删除不满足条件的孤立段\n",
    "    for node, features in list(updated_graph.nodes(data=True)):\n",
    "        if updated_graph.degree(node) == 0:\n",
    "            if features['pixel_count'] < min_pixel_count:\n",
    "                updated_graph.remove_node(node)\n",
    "                if(debug):\n",
    "                    print(f\"删除孤立节点: {node} - 像素数量低于阈值\")\n",
    "\n",
    "                # 2. 顶点获取坐标\n",
    "                point1, point2 = features['endpoints']\n",
    "                # 3. 拟合直线路径\n",
    "                pixels = generate_line_pixels(point1, point2)\n",
    "                for pixel in pixels:\n",
    "                    # 4. 设置对应坐标处权重\n",
    "                    if 0 <= pixel[0] < feature_map.shape[0] and 0 <= pixel[1] < feature_map.shape[1]:\n",
    "                        feature_map[pixel[0], pixel[1]] = 0.1\n",
    "                        if(debug):\n",
    "                            print(f\"设置权重: feature_map[{pixel[0]}, {pixel[1]}] = 0.1\")  # 打印日志\n",
    "\n",
    "    return updated_graph, feature_map\n",
    "# 应用高斯核\n",
    "def apply_gaussian_to_pixels(feature_map, sigma=3.0):\n",
    "    \"\"\"\n",
    "    对 feature_map 中的非零像素点应用高斯核扩展权重范围。\n",
    "    \n",
    "    参数:\n",
    "    - feature_map: np.array, 输入的特征图。\n",
    "    - sigma: float, 高斯核的标准差 (默认: 2.0)。\n",
    "    \n",
    "    返回:\n",
    "    - expanded_feature_map: np.array, 经过高斯扩展后的特征图。\n",
    "    \"\"\"\n",
    "    # 创建一个与 feature_map 大小相同的空图像\n",
    "    expanded_feature_map = np.zeros_like(feature_map) * 3\n",
    "    \n",
    "    # 获取所有非零像素的位置\n",
    "    non_zero_pixels = np.argwhere(feature_map > 0)\n",
    "    \n",
    "    # 对每个非零像素点应用高斯核\n",
    "    for pixel in non_zero_pixels:\n",
    "        temp_map = np.zeros_like(feature_map)\n",
    "        temp_map[pixel[0], pixel[1]] = feature_map[pixel[0], pixel[1]]\n",
    "        # 应用高斯滤波器在这个点上扩散\n",
    "        expanded_feature_map += gaussian_filter(temp_map, sigma=sigma)\n",
    "    \n",
    "    return expanded_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logits Gradient:\n",
      "tensor([[[[7.0583e-06, 7.0583e-06, 7.0583e-06,  ..., 7.0583e-06,\n",
      "           7.0583e-06, 7.0583e-06],\n",
      "          [7.0583e-06, 7.0583e-06, 7.0583e-06,  ..., 7.0583e-06,\n",
      "           7.0583e-06, 7.0583e-06],\n",
      "          [7.0583e-06, 7.0583e-06, 7.0583e-06,  ..., 7.0583e-06,\n",
      "           7.0583e-06, 7.0583e-06],\n",
      "          ...,\n",
      "          [7.0583e-06, 7.0583e-06, 7.0583e-06,  ..., 7.0583e-06,\n",
      "           7.0583e-06, 7.0583e-06],\n",
      "          [7.0583e-06, 7.0583e-06, 7.0583e-06,  ..., 7.0583e-06,\n",
      "           7.0583e-06, 7.0583e-06],\n",
      "          [7.0583e-06, 7.0583e-06, 7.0583e-06,  ..., 7.0583e-06,\n",
      "           7.0583e-06, 7.0583e-06]]]])\n",
      "Cross-Entropy Loss: 0.41038477420806885\n",
      "Weighted Cross-Entropy Loss: 0.4182465672492981\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class WeightedLossWithPrior(nn.Module):\n",
    "    def __init__(self, base_loss_fn,gradDebug=False):\n",
    "        \"\"\"\n",
    "        初始化带有先验信息加权的损失函数。\n",
    "\n",
    "        参数:\n",
    "        - base_loss_fn: 基础损失函数 (如 nn.CrossEntropyLoss)。\n",
    "        \"\"\"\n",
    "        super(WeightedLossWithPrior, self).__init__()\n",
    "        self.base_loss_fn = base_loss_fn\n",
    "        self.gradDebug = gradDebug\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \"\"\"\n",
    "        计算带有先验加权的损失值。\n",
    "\n",
    "        参数:\n",
    "        - logits: torch.Tensor, 模型输出的 logits，形状为 [B, C, H, W]。\n",
    "        - targets: torch.Tensor, 真实标签，形状为 [B, H, W]。\n",
    "\n",
    "        返回:\n",
    "        - loss: 计算得到的加权损失。\n",
    "        \"\"\"\n",
    "        # 转换输入数据为 PyTorch 张量并设置梯度\n",
    "        logits_t = torch.from_numpy(logits).float().unsqueeze(0).unsqueeze(0).to('cpu').requires_grad_(True)\n",
    "        targets_t = torch.from_numpy(targets).long().unsqueeze(0).to('cpu')\n",
    "\n",
    "        # 使用 no_grad 进行不影响梯度的处理\n",
    "        with torch.no_grad():\n",
    "            logits_arr = logits_t.detach().cpu().numpy().squeeze(0).squeeze(0)\n",
    "            if logits_arr.max() <= 1:\n",
    "                pred = (logits_arr * 255).astype(np.uint8)\n",
    "\n",
    "            _, binary = cv2.threshold(pred, 127, 255, cv2.THRESH_BINARY)\n",
    "            segment_graph = segment_and_visualize_vessels(binary.copy(), debug=False)\n",
    "            updated_graph, feature_map = apply_static_graph_rules(pred, segment_graph, debug=False)\n",
    "            expanded_gaussian_feature_map = apply_gaussian_to_pixels(feature_map)\n",
    "\n",
    "        # 转换为 PyTorch 张量\n",
    "        expanded_gaussian_feature_map_tensor = torch.tensor(expanded_gaussian_feature_map, dtype=torch.float32, device='cpu').unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # 模拟两个通道的 logits (C=2)\n",
    "        logits_two_channel = torch.cat([(1 - logits_t), logits_t], dim=1)\n",
    "\n",
    "        # 计算基础的交叉熵损失\n",
    "        base_loss = self.base_loss_fn(logits_two_channel, targets_t)\n",
    "\n",
    "        # 直接使用 feature_map 作为权重\n",
    "        weights = expanded_gaussian_feature_map_tensor + 1\n",
    "\n",
    "        # 计算加权后的损失并取平均\n",
    "        weighted_loss = (base_loss * weights).mean()\n",
    "\n",
    "        if(self.gradDebug):\n",
    "            # 反向传播\n",
    "            weighted_loss.backward() \n",
    "            print(\"\\nLogits Gradient:\")\n",
    "            print(logits_t.grad)\n",
    "        \n",
    "        return base_loss.mean(), weighted_loss\n",
    "    \n",
    "# 测试函数\n",
    "def test_weighted_loss_with_prior():\n",
    "    # 获取连通组件的预测图像和真实标签图像路径\n",
    "    path_pred = '/home/pxl/myProject/血管分割/molong-深度插值/molong-utils/数据集以及结果处理/pred.png'\n",
    "    path_true = '/home/pxl/myProject/血管分割/molong-深度插值/molong-utils/数据集以及结果处理/true.png'\n",
    "\n",
    "    # 裁剪区域的位置和大小\n",
    "    position = (160, 160)  # 裁剪的起始位置 (x, y)\n",
    "    size = (300, 300)  # 裁剪区域的尺寸 (width, height)\n",
    "    # 裁剪图像\n",
    "    cropped_image_pred = crop_image(path_pred, position, size, True)\n",
    "    cropped_image_true = crop_image(path_true, position, size, True)\n",
    "    \n",
    "    # 并转换为 numpy 数组、归一化、label化\n",
    "    pred_as_logits = np.array(cropped_image_pred, dtype=np.float32) / 255.0  # 归一化到 [0, 1] 范围\n",
    "    true = np.array(cropped_image_true, dtype=np.int64)  # 确保标签是整数类型\n",
    "    # 将 targets 从 [0, 255] 转换为 [0, 1]\n",
    "    true[true > 0] = 1\n",
    "    \n",
    "    # 调用 weighted_loss_with_prior 函数\n",
    "    base_loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "    mylossClass = WeightedLossWithPrior(base_loss_fn,gradDebug=True)\n",
    "    \n",
    "    Loss, weightedLoss = mylossClass(pred_as_logits, true)\n",
    "    \n",
    "    print(\"Cross-Entropy Loss:\", Loss.item())\n",
    "    print(\"Weighted Cross-Entropy Loss:\", weightedLoss.item())\n",
    "    \n",
    "\n",
    "# 运行测试用例\n",
    "test_weighted_loss_with_prior()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
